{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Build Regression Models</h1>\n",
    "<h2 style=\"text-align:center\">Applied Question 8</h2>\n",
    "<p style=\"text-align:center\">Robert Evans</p>\n",
    "<p style=\"text-align:center\">School of Technology & Engineering, National University</p>\n",
    "<p style=\"text-align:center\">DDS-8555: Predictive Analysis</p>\n",
    "<p style=\"text-align:center\">Dr. Mohammad Yavarimanesh</p>\n",
    "<p style=\"text-align:center\">January 26, 2025</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for repeatability\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictor X and noise vector epsilon\n",
    "n = 100\n",
    "X = np.random.normal(size=n)\n",
    "epsilon = np.random.normal(size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coefficients\n",
    "beta_0 = 2\n",
    "beta_1 = 3\n",
    "beta_2 = -1\n",
    "beta_3 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate response vector Y\n",
    "Y =  beta_0 + beta_1 * X + beta_2 * X**2 + beta_3 * X**3 + epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a design matrix with X, X^2, ..., X^10\n",
    "X_poly = np.column_stack([X**i for i in range(1, 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_stepwise_selection(X, Y):\n",
    "    \"\"\"\n",
    "    Perform forward stepwise selection to select predictors for regression.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): The predictor matrix.\n",
    "        Y (numpy.ndarray): The response vector.\n",
    "\n",
    "    Returns:\n",
    "        selected_model (LinearRegression): The final model selected.\n",
    "        predictors (list): Indices of selected predictors.\n",
    "    \"\"\"\n",
    "    predictors = []  # Start with no predictors selected\n",
    "    min_cp = float(\"inf\")  # Initialize the minimum Cp to a very large value\n",
    "    selected_model = None  # Placeholder for the final selected model\n",
    "    n = len(Y)  # Number of observations\n",
    "\n",
    "    # Iterate over the number of predictors\n",
    "    for _ in range(X.shape[1]):\n",
    "        best_cp = float(\"inf\")  # Initialize the best Cp for this iteration\n",
    "        best_model = None  # Placeholder for the best model in this iteration\n",
    "        best_predictors = None  # Placeholder for the best set of predictors\n",
    "\n",
    "        # Test each predictor not already in the model\n",
    "        for i in range(X.shape[1]):\n",
    "            if i not in predictors:\n",
    "                # Create a list of current predictors by adding the new predictor\n",
    "                current_predictors = predictors + [i]\n",
    "                \n",
    "                # Extract the columns corresponding to the current predictors\n",
    "                X_subset = X[:, current_predictors]\n",
    "                \n",
    "                # Fit a linear regression model on the subset of predictors\n",
    "                model = LinearRegression().fit(X_subset, Y)\n",
    "                y_pred = model.predict(X_subset)  # Generate predictions\n",
    "                \n",
    "                # Calculate Residual Sum of Squares (RSS)\n",
    "                rss = sum((Y - y_pred) ** 2)\n",
    "                \n",
    "                # Compute Mallows' Cp (a measure of model quality)\n",
    "                cp = rss + 2 * (len(current_predictors) + 1) * np.var(Y)\n",
    "                \n",
    "                # If this model is better (lower Cp), update the best model\n",
    "                if cp < best_cp:\n",
    "                    best_cp = cp\n",
    "                    best_model = model\n",
    "                    best_predictors = current_predictors\n",
    "\n",
    "        # Update the selected predictors and the final model if Cp improves\n",
    "        predictors = best_predictors\n",
    "        if best_cp < min_cp:\n",
    "            min_cp = best_cp\n",
    "            selected_model = best_model\n",
    "\n",
    "        # Print progress for each step\n",
    "        print(f\"Step {len(predictors)}: Added predictor {predictors[-1]} with Cp = {min_cp}\")\n",
    "\n",
    "    # Return the final selected model and predictors\n",
    "    return selected_model, predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Added predictor 2 with Cp = 377.2770747678594\n",
      "Step 2: Added predictor 0 with Cp = 251.31959202807815\n",
      "Step 3: Added predictor 1 with Cp = 236.79744065727735\n",
      "Step 4: Added predictor 9 with Cp = 236.79744065727735\n",
      "Step 5: Added predictor 4 with Cp = 236.79744065727735\n",
      "Step 6: Added predictor 8 with Cp = 236.79744065727735\n",
      "Step 7: Added predictor 3 with Cp = 236.79744065727735\n",
      "Step 8: Added predictor 7 with Cp = 236.79744065727735\n",
      "Step 9: Added predictor 5 with Cp = 236.79744065727735\n",
      "Step 10: Added predictor 6 with Cp = 236.79744065727735\n",
      "Forward Stepwise Predictors: [2, 0, 1, 9, 4, 8, 3, 7, 5, 6]\n",
      "Coefficients: [ 0.52836644  2.8642927  -0.79306238]\n"
     ]
    }
   ],
   "source": [
    "forward_model, forward_predictors = forward_stepwise_selection(X_poly, Y)\n",
    "print(\"Forward Stepwise Predictors:\", forward_predictors)\n",
    "print(\"Coefficients:\", forward_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_stepwise_selection(X, Y):\n",
    "    \"\"\"\n",
    "    Perform backward stepwise selection to select predictors for regression.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): The predictor matrix.\n",
    "        Y (numpy.ndarray): The response vector.\n",
    "\n",
    "    Returns:\n",
    "        selected_model (LinearRegression): The final model selected.\n",
    "        predictors (list): Indices of selected predictors.\n",
    "    \"\"\"\n",
    "    # Start with all predictors initially included in the model\n",
    "    predictors = list(range(X.shape[1]))\n",
    "    min_cp = float(\"inf\")  # Initialize the minimum Cp to a very large value\n",
    "    selected_model = None  # Placeholder for the final selected model\n",
    "    n = len(Y)  # Number of observations\n",
    "\n",
    "    # Iterate until we have no predictors to remove\n",
    "    while len(predictors) > 0:\n",
    "        best_cp = float(\"inf\")  # Initialize the best Cp for this iteration\n",
    "        best_model = None  # Placeholder for the best model in this iteration\n",
    "        best_predictors = None  # Placeholder for the best set of predictors\n",
    "\n",
    "        # Test the model with each predictor removed\n",
    "        for i in predictors:\n",
    "            # Create a list of current predictors by removing one predictor\n",
    "            current_predictors = [p for p in predictors if p != i]\n",
    "            \n",
    "            # Extract the columns corresponding to the current predictors\n",
    "            X_subset = X[:, current_predictors]\n",
    "            \n",
    "            # Fit a linear regression model on the subset of predictors\n",
    "            model = LinearRegression().fit(X_subset, Y)\n",
    "            y_pred = model.predict(X_subset)  # Generate predictions\n",
    "            \n",
    "            # Calculate Residual Sum of Squares (RSS)\n",
    "            rss = sum((Y - y_pred) ** 2)\n",
    "            \n",
    "            # Compute Mallows' Cp (a measure of model quality)\n",
    "            cp = rss + 2 * (len(current_predictors) + 1) * np.var(Y)\n",
    "            \n",
    "            # If this model is better (lower Cp), update the best model\n",
    "            if cp < best_cp:\n",
    "                best_cp = cp\n",
    "                best_model = model\n",
    "                best_predictors = current_predictors\n",
    "\n",
    "        # Update the selected predictors and the final model if Cp improves\n",
    "        predictors = best_predictors\n",
    "        if best_cp < min_cp:\n",
    "            min_cp = best_cp\n",
    "            selected_model = best_model\n",
    "\n",
    "        # Print progress for each step\n",
    "        print(f\"Step {len(predictors)}: Removed predictor {i} with Cp = {min_cp}\")\n",
    "\n",
    "    # Return the final selected model and predictors\n",
    "    return selected_model, predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9: Removed predictor 9 with Cp = 459.79967745107416\n",
      "Step 8: Removed predictor 9 with Cp = 421.66246429349377\n",
      "Step 7: Removed predictor 9 with Cp = 383.7795759122897\n",
      "Step 6: Removed predictor 9 with Cp = 346.86094134618656\n",
      "Step 5: Removed predictor 9 with Cp = 308.9371290662358\n",
      "Step 4: Removed predictor 9 with Cp = 283.86508326048545\n",
      "Step 3: Removed predictor 7 with Cp = 256.0500575519655\n",
      "Step 2: Removed predictor 7 with Cp = 237.26390701196368\n",
      "Step 1: Removed predictor 5 with Cp = 237.26390701196368\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(100, 0)) while a minimum of 1 is required by LinearRegression.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m backward_model, backward_predictors \u001b[38;5;241m=\u001b[39m \u001b[43mbackward_stepwise_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_poly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackward Stepwise Predictors:\u001b[39m\u001b[38;5;124m\"\u001b[39m, backward_predictors)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoefficients:\u001b[39m\u001b[38;5;124m\"\u001b[39m, backward_model\u001b[38;5;241m.\u001b[39mcoef_)\n",
      "Cell \u001b[1;32mIn[15], line 34\u001b[0m, in \u001b[0;36mbackward_stepwise_selection\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m     31\u001b[0m X_subset \u001b[38;5;241m=\u001b[39m X[:, current_predictors]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Fit a linear regression model on the subset of predictors\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_subset)  \u001b[38;5;66;03m# Generate predictions\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Calculate Residual Sum of Squares (RSS)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_base.py:609\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    605\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    607\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 609\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1096\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1094\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m<\u001b[39m ensure_min_features:\n\u001b[1;32m-> 1096\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1097\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1098\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1099\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m   1100\u001b[0m         )\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_writeable:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;66;03m# By default, array.copy() creates a C-ordered copy. We set order=K to\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;66;03m# preserve the order of the array.\u001b[39;00m\n\u001b[0;32m   1105\u001b[0m     copy_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array) \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(100, 0)) while a minimum of 1 is required by LinearRegression."
     ]
    }
   ],
   "source": [
    "backward_model, backward_predictors = backward_stepwise_selection(X_poly, Y)\n",
    "print(\"Backward Stepwise Predictors:\", backward_predictors)\n",
    "print(\"Coefficients:\", backward_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
